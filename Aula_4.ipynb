{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN9EOT3G1UwLssgFu0+Najg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabio-baum/ia_para_engenheiros2/blob/main/Aula_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwSzxaZg7qV9"
      },
      "outputs": [],
      "source": [
        "# Step 1: Install and import necessary libraries\n",
        "!pip install pandas numpy matplotlib seaborn scikit-learn openpyxl\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import io\n",
        "\n",
        "print(\"Libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Upload and load the Excel file\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Load the Excel file\n",
        "file_name = list(uploaded.keys())[0]\n",
        "df = pd.read_excel(file_name, sheet_name='Database-CdSe-V')\n",
        "\n",
        "print(\"File loaded successfully!\")\n",
        "print(f\"Dataset shape: {df.shape}\")"
      ],
      "metadata": {
        "id": "0hizC0wT736G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Explore the dataset\n",
        "print(\"Dataset Info:\")\n",
        "print(df.info())\n",
        "\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nDataset columns:\")\n",
        "print(df.columns.tolist())"
      ],
      "metadata": {
        "id": "OywdmiUy761g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Check for missing values and data types\n",
        "print(\"Missing values in each column:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "print(\"\\nData types:\")\n",
        "print(df.dtypes)"
      ],
      "metadata": {
        "id": "6Fl_94gp7_EM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Data preprocessing - Handle missing values and select numerical columns\n",
        "# Drop columns with too many missing values or non-numeric data\n",
        "df_clean = df.copy()\n",
        "\n",
        "# Remove columns with all missing values or mostly text\n",
        "columns_to_drop = []\n",
        "for col in df_clean.columns:\n",
        "    if df_clean[col].isnull().sum() > len(df_clean) * 0.5:  # Drop if more than 50% missing\n",
        "        columns_to_drop.append(col)\n",
        "    elif df_clean[col].dtype == 'object' and col != 'Citation':\n",
        "        # Check if column contains mostly text (not convertible to numeric)\n",
        "        try:\n",
        "            pd.to_numeric(df_clean[col], errors='raise')\n",
        "        except:\n",
        "            columns_to_drop.append(col)\n",
        "\n",
        "df_clean = df_clean.drop(columns=columns_to_drop)\n",
        "print(f\"Dropped columns: {columns_to_drop}\")\n",
        "\n",
        "# Convert remaining columns to numeric, coercing errors to NaN\n",
        "for col in df_clean.columns:\n",
        "    if col != 'Citation':\n",
        "        df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')\n",
        "\n",
        "# Drop rows where target variable (Diameter_nm) is missing\n",
        "df_clean = df_clean.dropna(subset=['Diameter_nm'])\n",
        "\n",
        "print(f\"Cleaned dataset shape: {df_clean.shape}\")"
      ],
      "metadata": {
        "id": "THKjHZ0l8DKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Separate features and target variable\n",
        "# Target variable: Diameter_nm\n",
        "target = 'Diameter_nm'\n",
        "\n",
        "# Remove non-feature columns\n",
        "non_feature_cols = ['Citation']  # Add other non-feature columns if needed\n",
        "features = [col for col in df_clean.columns if col not in [target] + non_feature_cols]\n",
        "\n",
        "print(\"Features to use:\", features)\n",
        "print(f\"Number of features: {len(features)}\")\n",
        "\n",
        "X = df_clean[features]\n",
        "y = df_clean[target]\n",
        "\n",
        "# Handle missing values in features by imputing with mean\n",
        "X = X.fillna(X.mean())\n",
        "\n",
        "print(f\"Final feature matrix shape: {X.shape}\")\n",
        "print(f\"Target variable shape: {y.shape}\")"
      ],
      "metadata": {
        "id": "4oAKd-sX8K6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Training set size: {X_train.shape[0]}\")\n",
        "print(f\"Testing set size: {X_test.shape[0]}\")"
      ],
      "metadata": {
        "id": "JGo7-taa8QI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: SIMPLE LINEAR REGRESSION - Using single most correlated feature\n",
        "# Find the feature most correlated with diameter\n",
        "correlations = X.corrwith(y).abs().sort_values(ascending=False)\n",
        "best_feature = correlations.index[0]\n",
        "\n",
        "print(\"Top 5 features correlated with Diameter_nm:\")\n",
        "print(correlations.head())\n",
        "\n",
        "print(f\"\\nSelected feature for simple linear regression: {best_feature}\")"
      ],
      "metadata": {
        "id": "AXsBx3lB8VQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Simple Linear Regression Model\n",
        "# Prepare data for simple linear regression\n",
        "X_simple_train = X_train[[best_feature]]\n",
        "X_simple_test = X_test[[best_feature]]\n",
        "\n",
        "# Create and train the model\n",
        "simple_model = LinearRegression()\n",
        "simple_model.fit(X_simple_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_simple = simple_model.predict(X_simple_test)\n",
        "\n",
        "print(\"Simple Linear Regression Results:\")\n",
        "print(f\"Coefficient: {simple_model.coef_[0]:.4f}\")\n",
        "print(f\"Intercept: {simple_model.intercept_:.4f}\")"
      ],
      "metadata": {
        "id": "AMwNtra78WK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 10: Evaluate Simple Linear Regression\n",
        "def calculate_metrics(y_true, y_pred, model_name):\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "\n",
        "    metrics = {\n",
        "        'R2': r2,\n",
        "        'MAE': mae,\n",
        "        'RMSE': rmse,\n",
        "        'MAPE': mape\n",
        "    }\n",
        "\n",
        "    print(f\"\\n{model_name} Metrics:\")\n",
        "    print(f\"R² Score: {r2:.4f}\")\n",
        "    print(f\"MAE: {mae:.4f}\")\n",
        "    print(f\"RMSE: {rmse:.4f}\")\n",
        "    print(f\"MAPE: {mape:.2f}%\")\n",
        "\n",
        "    return metrics\n",
        "\n",
        "simple_metrics = calculate_metrics(y_test, y_pred_simple, \"Simple Linear Regression\")"
      ],
      "metadata": {
        "id": "oIamD8O78Zqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 11: Visualize Simple Linear Regression Results\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Plot 1: Actual vs Predicted\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.scatter(y_test, y_pred_simple, alpha=0.6)\n",
        "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2)\n",
        "plt.xlabel('Actual Diameter (nm)')\n",
        "plt.ylabel('Predicted Diameter (nm)')\n",
        "plt.title('Simple Linear Regression: Actual vs Predicted')\n",
        "\n",
        "# Plot 2: Residuals\n",
        "plt.subplot(1, 3, 2)\n",
        "residuals = y_test - y_pred_simple\n",
        "plt.scatter(y_pred_simple, residuals, alpha=0.6)\n",
        "plt.axhline(y=0, color='r', linestyle='--')\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('Residual Plot')\n",
        "\n",
        "# Plot 3: Feature vs Target\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.scatter(X_simple_test[best_feature], y_test, alpha=0.6, label='Actual')\n",
        "plt.scatter(X_simple_test[best_feature], y_pred_simple, alpha=0.6, label='Predicted')\n",
        "plt.xlabel(best_feature)\n",
        "plt.ylabel('Diameter (nm)')\n",
        "plt.legend()\n",
        "plt.title(f'{best_feature} vs Diameter')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "a0Cl60iw8fQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 12: MULTIPLE LINEAR REGRESSION\n",
        "# Scale the features for better performance\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Create and train multiple linear regression model\n",
        "multi_model = LinearRegression()\n",
        "multi_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_multi = multi_model.predict(X_test_scaled)\n",
        "\n",
        "print(\"Multiple Linear Regression Model Trained!\")\n",
        "print(f\"Number of features used: {len(features)}\")"
      ],
      "metadata": {
        "id": "Q_gP0CSB8jKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 13: Evaluate Multiple Linear Regression\n",
        "multi_metrics = calculate_metrics(y_test, y_pred_multi, \"Multiple Linear Regression\")"
      ],
      "metadata": {
        "id": "i4a3qwl18mFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 14: Compare Model Performance\n",
        "metrics_comparison = pd.DataFrame({\n",
        "    'Simple Linear Regression': simple_metrics,\n",
        "    'Multiple Linear Regression': multi_metrics\n",
        "})\n",
        "\n",
        "print(\"Model Performance Comparison:\")\n",
        "print(metrics_comparison)"
      ],
      "metadata": {
        "id": "rCO4jT3t8pJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 15: Visualize Multiple Linear Regression Results\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Plot 1: Actual vs Predicted\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.scatter(y_test, y_pred_multi, alpha=0.6)\n",
        "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2)\n",
        "plt.xlabel('Actual Diameter (nm)')\n",
        "plt.ylabel('Predicted Diameter (nm)')\n",
        "plt.title('Multiple Linear Regression: Actual vs Predicted')\n",
        "\n",
        "# Plot 2: Residuals\n",
        "plt.subplot(1, 3, 2)\n",
        "residuals_multi = y_test - y_pred_multi\n",
        "plt.scatter(y_pred_multi, residuals_multi, alpha=0.6)\n",
        "plt.axhline(y=0, color='r', linestyle='--')\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('Residual Plot')\n",
        "\n",
        "# Plot 3: Comparison of both models\n",
        "plt.subplot(1, 3, 3)\n",
        "models = ['Simple LR', 'Multiple LR']\n",
        "r2_scores = [simple_metrics['R2'], multi_metrics['R2']]\n",
        "mae_scores = [simple_metrics['MAE'], multi_metrics['MAE']]\n",
        "\n",
        "x = np.arange(len(models))\n",
        "width = 0.35\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "rects1 = ax.bar(x - width/2, r2_scores, width, label='R²', alpha=0.7)\n",
        "rects2 = ax.bar(x + width/2, mae_scores, width, label='MAE', alpha=0.7)\n",
        "\n",
        "ax.set_ylabel('Scores')\n",
        "ax.set_title('Model Comparison: R² and MAE')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(models)\n",
        "ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "n8nEP3Bf8q_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 16: Feature Importance Analysis\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': features,\n",
        "    'Coefficient': multi_model.coef_,\n",
        "    'Absolute_Coefficient': np.abs(multi_model.coef_)\n",
        "})\n",
        "\n",
        "feature_importance = feature_importance.sort_values('Absolute_Coefficient', ascending=False)\n",
        "\n",
        "print(\"Top 10 Most Important Features:\")\n",
        "print(feature_importance.head(10))"
      ],
      "metadata": {
        "id": "HEBLl3Y38trw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 17: Visualize Feature Importance\n",
        "plt.figure(figsize=(10, 8))\n",
        "top_features = feature_importance.head(10)\n",
        "\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.barh(top_features['Feature'], top_features['Coefficient'])\n",
        "plt.xlabel('Coefficient Value')\n",
        "plt.title('Top 10 Feature Coefficients')\n",
        "plt.gca().invert_yaxis()\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.barh(top_features['Feature'], top_features['Absolute_Coefficient'])\n",
        "plt.xlabel('Absolute Coefficient Value')\n",
        "plt.title('Top 10 Feature Importance (Absolute Coefficients)')\n",
        "plt.gca().invert_yaxis()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GgAUrGJF8yBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 18: Detailed Error Analysis\n",
        "print(\"Detailed Error Analysis:\")\n",
        "\n",
        "# Create comparison dataframe\n",
        "results_df = pd.DataFrame({\n",
        "    'Actual': y_test.values,\n",
        "    'Predicted_Simple': y_pred_simple,\n",
        "    'Predicted_Multiple': y_pred_multi\n",
        "})\n",
        "\n",
        "results_df['Error_Simple'] = results_df['Actual'] - results_df['Predicted_Simple']\n",
        "results_df['Error_Multiple'] = results_df['Actual'] - results_df['Predicted_Multiple']\n",
        "results_df['Absolute_Error_Simple'] = np.abs(results_df['Error_Simple'])\n",
        "results_df['Absolute_Error_Multiple'] = np.abs(results_df['Error_Multiple'])\n",
        "\n",
        "print(\"\\nSample of Predictions and Errors:\")\n",
        "print(results_df.head(10))\n",
        "\n",
        "print(f\"\\nSummary Statistics for Errors:\")\n",
        "print(\"Simple Linear Regression:\")\n",
        "print(f\"Mean Absolute Error: {results_df['Absolute_Error_Simple'].mean():.4f}\")\n",
        "print(f\"Std of Errors: {results_df['Error_Simple'].std():.4f}\")\n",
        "\n",
        "print(\"\\nMultiple Linear Regression:\")\n",
        "print(f\"Mean Absolute Error: {results_df['Absolute_Error_Multiple'].mean():.4f}\")\n",
        "print(f\"Std of Errors: {results_df['Error_Multiple'].std():.4f}\")"
      ],
      "metadata": {
        "id": "bkrrkeFv80UX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 19: Final Summary\n",
        "print(\"=\"*60)\n",
        "print(\"FINAL REGRESSION ANALYSIS SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\nDataset Overview:\")\n",
        "print(f\"Total samples: {len(df)}\")\n",
        "print(f\"Features used: {len(features)}\")\n",
        "print(f\"Target variable: Diameter_nm\")\n",
        "\n",
        "print(f\"\\nBest Single Feature: {best_feature}\")\n",
        "print(f\"Correlation with target: {correlations[best_feature]:.4f}\")\n",
        "\n",
        "print(f\"\\nPerformance Summary:\")\n",
        "print(f\"{'Metric':<15} {'Simple LR':<15} {'Multiple LR':<15} {'Improvement':<15}\")\n",
        "print(\"-\" * 60)\n",
        "for metric in ['R2', 'MAE', 'RMSE', 'MAPE']:\n",
        "    simple_val = simple_metrics[metric]\n",
        "    multi_val = multi_metrics[metric]\n",
        "    improvement = ((simple_val - multi_val) / simple_val * 100) if metric != 'R2' else ((multi_val - simple_val) / simple_val * 100)\n",
        "\n",
        "    if metric == 'R2':\n",
        "        print(f\"{metric:<15} {simple_val:<15.4f} {multi_val:<15.4f} {improvement:>13.1f}%\")\n",
        "    else:\n",
        "        print(f\"{metric:<15} {simple_val:<15.4f} {multi_val:<15.4f} {improvement:>13.1f}%\")\n",
        "\n",
        "print(\"\\nConclusion:\")\n",
        "if multi_metrics['R2'] > simple_metrics['R2']:\n",
        "    print(\"✓ Multiple Linear Regression performs better than Simple Linear Regression\")\n",
        "else:\n",
        "    print(\"○ Simple Linear Regression performs similarly or better than Multiple Linear Regression\")\n",
        "\n",
        "print(f\"\\nThe best model explains {max(simple_metrics['R2'], multi_metrics['R2'])*100:.1f}% of the variance in nanoparticle diameter.\")"
      ],
      "metadata": {
        "id": "94GWzAKp83EA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}